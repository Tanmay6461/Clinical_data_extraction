[2025-05-13T20:01:53.996+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-05-13T20:01:54.013+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sec_filing_scheduler.process_alny manual__2025-05-13T20:01:47.115699+00:00 [queued]>
[2025-05-13T20:01:54.022+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sec_filing_scheduler.process_alny manual__2025-05-13T20:01:47.115699+00:00 [queued]>
[2025-05-13T20:01:54.023+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 4
[2025-05-13T20:01:54.040+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): process_alny> on 2025-05-13 20:01:47.115699+00:00
[2025-05-13T20:01:54.055+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=3272) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-05-13T20:01:54.057+0000] {standard_task_runner.py:72} INFO - Started process 3273 to run task
[2025-05-13T20:01:54.057+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'sec_filing_scheduler', 'process_alny', 'manual__2025-05-13T20:01:47.115699+00:00', '--job-id', '104', '--raw', '--subdir', 'DAGS_FOLDER/orchestrate_clinical_pipeline.py', '--cfg-path', '/tmp/tmpnknp1ixj']
[2025-05-13T20:01:54.060+0000] {standard_task_runner.py:105} INFO - Job 104: Subtask process_alny
[2025-05-13T20:01:54.117+0000] {task_command.py:467} INFO - Running <TaskInstance: sec_filing_scheduler.process_alny manual__2025-05-13T20:01:47.115699+00:00 [running]> on host c1a7243cf3b7
[2025-05-13T20:01:54.216+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sec_filing_scheduler' AIRFLOW_CTX_TASK_ID='process_alny' AIRFLOW_CTX_EXECUTION_DATE='2025-05-13T20:01:47.115699+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-13T20:01:47.115699+00:00'
[2025-05-13T20:01:54.218+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-05-13T20:01:54.268+0000] {connection.py:277} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2025-05-13T20:01:54.270+0000] {base.py:84} INFO - Retrieving connection 'google_cloud_default'
[2025-05-13T20:01:55.213+0000] {logging_mixin.py:190} INFO - Found 141 8-K filings
[2025-05-13T20:01:55.214+0000] {logging_mixin.py:190} INFO - Found 13 10-K filings
[2025-05-13T20:01:55.214+0000] {logging_mixin.py:190} INFO - Found 37 10-Q filings
[2025-05-13T20:01:55.215+0000] {logging_mixin.py:190} INFO - Found 191 new filings.
[2025-05-13T20:01:55.216+0000] {logging_mixin.py:190} INFO - Processing 191 filings...
[2025-05-13T20:01:55.219+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-25-000052
[2025-05-13T20:01:55.220+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-25-000050
[2025-05-13T20:01:55.417+0000] {logging_mixin.py:190} INFO - No sections found in 8-K filing 0001178670-25-000050
[2025-05-13T20:01:55.418+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-25-000050
[2025-05-13T20:01:55.420+0000] {logging_mixin.py:190} INFO - Finished 1/191: 0001178670-25-000050
[2025-05-13T20:01:55.421+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-25-000038
[2025-05-13T20:01:56.080+0000] {logging_mixin.py:190} INFO - No sections found in 8-K filing 0001178670-25-000038
[2025-05-13T20:01:56.086+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-25-000038
[2025-05-13T20:01:56.101+0000] {logging_mixin.py:190} INFO - Finished 2/191: 0001178670-25-000038
[2025-05-13T20:01:56.107+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-25-000031
[2025-05-13T20:01:56.282+0000] {logging_mixin.py:190} INFO - No sections found in 8-K filing 0001178670-25-000031
[2025-05-13T20:01:56.293+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-25-000031
[2025-05-13T20:01:56.305+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-25-000026
[2025-05-13T20:01:56.311+0000] {logging_mixin.py:190} INFO - Finished 3/191: 0001178670-25-000031
[2025-05-13T20:01:57.907+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:01:57.929+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.393507 seconds
[2025-05-13T20:01:58.552+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:01:58.565+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.814119 seconds
[2025-05-13T20:01:59.129+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:01:59.131+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.391916 seconds
[2025-05-13T20:01:59.625+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:01:59.641+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50838. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:01:59.642+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:01:59.844+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:01:59.846+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.952369 seconds
[2025-05-13T20:02:01.005+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:01.007+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50850. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:01.007+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:02:01.283+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:01.284+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.494436 seconds
[2025-05-13T20:02:01.948+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:01.949+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.995534 seconds
[2025-05-13T20:02:02.128+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:02.863+0000] {logging_mixin.py:190} INFO - Uploaded 10-Q filing to GCS: gs://clinical_data_may25/ALNY/10-Q/2025/ALNY_10-Q_2025-05-01_0001178670-25-000052.txt
[2025-05-13T20:02:03.168+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:03.169+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50830. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:03.169+0000] {logging_mixin.py:190} INFO - [Chunk 2] LLM response missing or failed.
[2025-05-13T20:02:03.377+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:03.378+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-25-000052
[2025-05-13T20:02:03.378+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.420310 seconds
[2025-05-13T20:02:03.379+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-25-000020
[2025-05-13T20:02:03.379+0000] {logging_mixin.py:190} INFO - Finished 4/191: 0001178670-25-000052
[2025-05-13T20:02:03.467+0000] {logging_mixin.py:190} INFO - No sections found in 8-K filing 0001178670-25-000020
[2025-05-13T20:02:03.467+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-25-000020
[2025-05-13T20:02:03.468+0000] {logging_mixin.py:190} INFO - Finished 5/191: 0001178670-25-000020
[2025-05-13T20:02:03.468+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-25-000008
[2025-05-13T20:02:03.626+0000] {logging_mixin.py:190} INFO - No sections found in 8-K filing 0001178670-25-000008
[2025-05-13T20:02:03.626+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-25-000008
[2025-05-13T20:02:03.627+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-24-000053
[2025-05-13T20:02:03.627+0000] {logging_mixin.py:190} INFO - Finished 6/191: 0001178670-25-000008
[2025-05-13T20:02:04.040+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:04.051+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.773383 seconds
[2025-05-13T20:02:04.826+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:04.828+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.452644 seconds
[2025-05-13T20:02:04.997+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:04.999+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 51224. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:05.000+0000] {logging_mixin.py:190} INFO - [Chunk 3] LLM response missing or failed.
[2025-05-13T20:02:05.485+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:05.754+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:05.755+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.878177 seconds
[2025-05-13T20:02:06.188+0000] {logging_mixin.py:190} INFO - Uploaded 10-K filing to GCS: gs://clinical_data_may25/ALNY/10-K/2025/ALNY_10-K_2025-02-13_0001178670-25-000026.txt
[2025-05-13T20:02:06.633+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-25-000026
[2025-05-13T20:02:06.634+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-24-000052
[2025-05-13T20:02:06.634+0000] {logging_mixin.py:190} INFO - Finished 7/191: 0001178670-25-000026
[2025-05-13T20:02:06.779+0000] {logging_mixin.py:190} INFO - No sections found in 8-K filing 0001178670-24-000052
[2025-05-13T20:02:06.780+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-24-000052
[2025-05-13T20:02:06.781+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-24-000041
[2025-05-13T20:02:06.782+0000] {logging_mixin.py:190} INFO - Finished 8/191: 0001178670-24-000052
[2025-05-13T20:02:06.843+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:06.844+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50839. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:06.845+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:02:07.384+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:08.157+0000] {logging_mixin.py:190} INFO - Uploaded 10-Q filing to GCS: gs://clinical_data_may25/ALNY/10-Q/2024/ALNY_10-Q_2024-10-31_0001178670-24-000053.txt
[2025-05-13T20:02:08.198+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:08.200+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.411025 seconds
[2025-05-13T20:02:08.646+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-24-000053
[2025-05-13T20:02:08.647+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-24-000039
[2025-05-13T20:02:08.647+0000] {logging_mixin.py:190} INFO - Finished 9/191: 0001178670-24-000053
[2025-05-13T20:02:08.802+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:08.803+0000] {logging_mixin.py:190} INFO - No sections found in 8-K filing 0001178670-24-000039
[2025-05-13T20:02:08.805+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.779262 seconds
[2025-05-13T20:02:08.806+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-24-000039
[2025-05-13T20:02:08.808+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-24-000027
[2025-05-13T20:02:08.809+0000] {logging_mixin.py:190} INFO - Finished 10/191: 0001178670-24-000039
[2025-05-13T20:02:08.967+0000] {logging_mixin.py:190} INFO - No sections found in 8-K filing 0001178670-24-000027
[2025-05-13T20:02:08.968+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-24-000027
[2025-05-13T20:02:08.969+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-24-000023
[2025-05-13T20:02:08.970+0000] {logging_mixin.py:190} INFO - Finished 11/191: 0001178670-24-000027
[2025-05-13T20:02:09.855+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:09.895+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50842. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:09.905+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:02:10.728+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:11.169+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:11.171+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.465676 seconds
[2025-05-13T20:02:11.373+0000] {logging_mixin.py:190} INFO - Uploaded 10-Q filing to GCS: gs://clinical_data_may25/ALNY/10-Q/2024/ALNY_10-Q_2024-08-01_0001178670-24-000041.txt
[2025-05-13T20:02:11.818+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:11.819+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.887482 seconds
[2025-05-13T20:02:11.840+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-24-000041
[2025-05-13T20:02:11.840+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-24-000021
[2025-05-13T20:02:11.841+0000] {logging_mixin.py:190} INFO - Finished 12/191: 0001178670-24-000041
[2025-05-13T20:02:11.936+0000] {logging_mixin.py:190} INFO - No sections found in 8-K filing 0001178670-24-000021
[2025-05-13T20:02:11.937+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-24-000021
[2025-05-13T20:02:11.938+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-24-057906
[2025-05-13T20:02:11.938+0000] {logging_mixin.py:190} INFO - Finished 13/191: 0001178670-24-000021
[2025-05-13T20:02:12.658+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:12.905+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:12.906+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50838. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:12.906+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:02:13.087+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2024/ALNY_8-K_2024-03-04_0001193125-24-057906.txt
[2025-05-13T20:02:13.480+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:13.575+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-24-057906
[2025-05-13T20:02:13.575+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-24-000008
[2025-05-13T20:02:13.575+0000] {logging_mixin.py:190} INFO - Finished 14/191: 0001193125-24-057906
[2025-05-13T20:02:14.032+0000] {logging_mixin.py:190} INFO - Uploaded 10-Q filing to GCS: gs://clinical_data_may25/ALNY/10-Q/2024/ALNY_10-Q_2024-05-02_0001178670-24-000023.txt
[2025-05-13T20:02:14.582+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-24-000023
[2025-05-13T20:02:14.583+0000] {logging_mixin.py:190} INFO - Finished 15/191: 0001178670-24-000023
[2025-05-13T20:02:14.583+0000] {logging_mixin.py:190} INFO - Processing filing: 0001157523-24-000253
[2025-05-13T20:02:14.647+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:14.649+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.426919 seconds
[2025-05-13T20:02:15.505+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:15.506+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.751822 seconds
[2025-05-13T20:02:15.798+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:16.302+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2024/ALNY_8-K_2024-02-15_0001157523-24-000253.txt
[2025-05-13T20:02:16.432+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:16.433+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50825. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:16.433+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:02:16.649+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:16.650+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.427247 seconds
[2025-05-13T20:02:16.767+0000] {logging_mixin.py:190} INFO - Finished processing: 0001157523-24-000253
[2025-05-13T20:02:16.767+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-24-011278
[2025-05-13T20:02:16.768+0000] {logging_mixin.py:190} INFO - Finished 16/191: 0001157523-24-000253
[2025-05-13T20:02:17.320+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:17.321+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.834868 seconds
[2025-05-13T20:02:17.346+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:17.810+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2024/ALNY_8-K_2024-01-19_0001193125-24-011278.txt
[2025-05-13T20:02:18.333+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-24-011278
[2025-05-13T20:02:18.335+0000] {logging_mixin.py:190} INFO - Finished 17/191: 0001193125-24-011278
[2025-05-13T20:02:18.334+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-24-003854
[2025-05-13T20:02:18.338+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:18.340+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50834. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:18.340+0000] {logging_mixin.py:190} INFO - [Chunk 2] LLM response missing or failed.
[2025-05-13T20:02:18.571+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:18.572+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.446338 seconds
[2025-05-13T20:02:19.222+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:19.223+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.756666 seconds
[2025-05-13T20:02:20.154+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:20.156+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 51211. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:20.157+0000] {logging_mixin.py:190} INFO - [Chunk 3] LLM response missing or failed.
[2025-05-13T20:02:21.347+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:22.117+0000] {logging_mixin.py:190} INFO - Uploaded 10-K filing to GCS: gs://clinical_data_may25/ALNY/10-K/2024/ALNY_10-K_2024-02-15_0001178670-24-000008.txt
[2025-05-13T20:02:22.581+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-24-000008
[2025-05-13T20:02:22.582+0000] {logging_mixin.py:190} INFO - Finished 18/191: 0001178670-24-000008
[2025-05-13T20:02:22.583+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-23-000023
[2025-05-13T20:02:25.237+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:25.338+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:25.339+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.412053 seconds
[2025-05-13T20:02:25.933+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:25.935+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2024/ALNY_8-K_2024-01-08_0001193125-24-003854.txt
[2025-05-13T20:02:25.936+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.997958 seconds
[2025-05-13T20:02:26.452+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-24-003854
[2025-05-13T20:02:26.453+0000] {logging_mixin.py:190} INFO - Finished 19/191: 0001193125-24-003854
[2025-05-13T20:02:26.454+0000] {logging_mixin.py:190} INFO - Processing filing: 0001157523-23-001622
[2025-05-13T20:02:27.129+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:27.131+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50840. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:27.132+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:02:27.647+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:28.107+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-11-02_0001157523-23-001622.txt
[2025-05-13T20:02:28.766+0000] {logging_mixin.py:190} INFO - Finished processing: 0001157523-23-001622
[2025-05-13T20:02:28.767+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-23-253084
[2025-05-13T20:02:28.768+0000] {logging_mixin.py:190} INFO - Finished 20/191: 0001157523-23-001622
[2025-05-13T20:02:29.473+0000] {local_task_job_runner.py:346} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2025-05-13T20:02:29.507+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-05-13T20:02:29.532+0000] {process_utils.py:132} INFO - Sending 15 to group 3273. PIDs of all processes in the group: [3273]
[2025-05-13T20:02:29.537+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 3273
[2025-05-13T20:02:29.538+0000] {taskinstance.py:3093} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-05-13T20:02:30.989+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:31.561+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-10-10_0001193125-23-253084.txt
[2025-05-13T20:02:32.117+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-23-253084
[2025-05-13T20:02:32.118+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-23-245768
[2025-05-13T20:02:32.954+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:33.430+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-09-28_0001193125-23-245768.txt
[2025-05-13T20:02:33.949+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-23-245768
[2025-05-13T20:02:33.950+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-23-000015
[2025-05-13T20:02:36.836+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:36.837+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.384654 seconds
[2025-05-13T20:02:37.420+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:37.422+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.936591 seconds
[2025-05-13T20:02:38.557+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:38.559+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50840. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:02:38.562+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:02:38.693+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:38.695+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 1.810000 seconds
[2025-05-13T20:02:45.005+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:45.748+0000] {logging_mixin.py:190} INFO - Uploaded 10-Q filing to GCS: gs://clinical_data_may25/ALNY/10-Q/2023/ALNY_10-Q_2023-11-02_0001178670-23-000023.txt
[2025-05-13T20:02:46.313+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-23-000023
[2025-05-13T20:02:46.314+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-23-202313
[2025-05-13T20:02:47.137+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:47.603+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-08-03_0001193125-23-202313.txt
[2025-05-13T20:02:48.095+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-23-202313
[2025-05-13T20:02:48.096+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-23-194715
[2025-05-13T20:02:48.345+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:02:48.346+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.034000 seconds
[2025-05-13T20:02:51.220+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:52.016+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-07-26_0001193125-23-194715.txt
[2025-05-13T20:02:52.557+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-23-194715
[2025-05-13T20:02:52.559+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-23-179631
[2025-05-13T20:02:55.397+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:55.872+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:55.970+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-06-30_0001193125-23-179631.txt
[2025-05-13T20:02:56.387+0000] {logging_mixin.py:190} INFO - Uploaded 10-Q filing to GCS: gs://clinical_data_may25/ALNY/10-Q/2023/ALNY_10-Q_2023-08-03_0001178670-23-000015.txt
[2025-05-13T20:02:56.425+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-23-179631
[2025-05-13T20:02:56.426+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-23-151845
[2025-05-13T20:02:56.929+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-23-000015
[2025-05-13T20:02:56.930+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-23-000011
[2025-05-13T20:02:57.154+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:02:57.865+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-05-23_0001193125-23-151845.txt
[2025-05-13T20:02:58.923+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-23-151845
[2025-05-13T20:02:58.935+0000] {logging_mixin.py:190} INFO - Processing filing: 0001157523-23-000728
[2025-05-13T20:02:59.689+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:03:00.358+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:00.360+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.474356 seconds
[2025-05-13T20:03:00.393+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-05-04_0001157523-23-000728.txt
[2025-05-13T20:03:00.892+0000] {logging_mixin.py:190} INFO - Finished processing: 0001157523-23-000728
[2025-05-13T20:03:00.895+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-23-064580
[2025-05-13T20:03:01.081+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:01.083+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.942014 seconds
[2025-05-13T20:03:01.663+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:03:02.180+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-03-08_0001193125-23-064580.txt
[2025-05-13T20:03:02.269+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:02.273+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 51092. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:03:02.274+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:03:02.449+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:02.452+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.473911 seconds
[2025-05-13T20:03:02.653+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-23-064580
[2025-05-13T20:03:02.655+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-23-000005
[2025-05-13T20:03:03.239+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:03.257+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.942960 seconds
[2025-05-13T20:03:04.398+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:04.405+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 37150. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:03:04.417+0000] {logging_mixin.py:190} INFO - [Chunk 2] LLM response missing or failed.
[2025-05-13T20:03:08.000+0000] {logging_mixin.py:190} INFO - Uploaded 10-Q filing to GCS: gs://clinical_data_may25/ALNY/10-Q/2023/ALNY_10-Q_2023-05-04_0001178670-23-000011.txt
[2025-05-13T20:03:08.726+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-23-000011
[2025-05-13T20:03:08.737+0000] {logging_mixin.py:190} INFO - Processing filing: 0001157523-23-000344
[2025-05-13T20:03:09.541+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:03:09.829+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:09.830+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.463449 seconds
[2025-05-13T20:03:10.050+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-02-23_0001157523-23-000344.txt
[2025-05-13T20:03:10.496+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:10.497+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.979858 seconds
[2025-05-13T20:03:10.507+0000] {logging_mixin.py:190} INFO - Finished processing: 0001157523-23-000344
[2025-05-13T20:03:10.508+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-23-004109
[2025-05-13T20:03:11.689+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:11.690+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50818. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:03:11.691+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:03:11.987+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:11.989+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.420976 seconds
[2025-05-13T20:03:12.617+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:12.618+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.874059 seconds
[2025-05-13T20:03:13.713+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:13.715+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 50834. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:03:13.715+0000] {logging_mixin.py:190} INFO - [Chunk 2] LLM response missing or failed.
[2025-05-13T20:03:13.896+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:13.898+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.406459 seconds
[2025-05-13T20:03:14.497+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:14.498+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.812227 seconds
[2025-05-13T20:03:15.455+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:03:15.520+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:15.521+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 51212. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:03:15.522+0000] {logging_mixin.py:190} INFO - [Chunk 3] LLM response missing or failed.
[2025-05-13T20:03:15.692+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:15.693+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 2.062000 seconds
[2025-05-13T20:03:15.928+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-01-09_0001193125-23-004109.txt
[2025-05-13T20:03:16.385+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-23-004109
[2025-05-13T20:03:16.386+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-23-003554
[2025-05-13T20:03:17.094+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:03:17.549+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2023/ALNY_8-K_2023-01-06_0001193125-23-003554.txt
[2025-05-13T20:03:17.970+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:17.972+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 3.078000 seconds
[2025-05-13T20:03:17.998+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-23-003554
[2025-05-13T20:03:17.999+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-22-000026
[2025-05-13T20:03:20.122+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:20.124+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.426808 seconds
[2025-05-13T20:03:20.736+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:20.737+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.753276 seconds
[2025-05-13T20:03:21.812+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:21.813+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 51245. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:03:21.813+0000] {logging_mixin.py:190} INFO - [Chunk 1] LLM response missing or failed.
[2025-05-13T20:03:22.040+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:22.041+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.414897 seconds
[2025-05-13T20:03:22.085+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:03:22.686+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:22.687+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 0.965200 seconds
[2025-05-13T20:03:22.808+0000] {logging_mixin.py:190} INFO - Uploaded 10-K filing to GCS: gs://clinical_data_may25/ALNY/10-K/2023/ALNY_10-K_2023-02-23_0001178670-23-000005.txt
[2025-05-13T20:03:23.307+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-23-000005
[2025-05-13T20:03:23.307+0000] {logging_mixin.py:190} INFO - Processing filing: 0001157523-22-001411
[2025-05-13T20:03:23.826+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:23.827+0000] {logging_mixin.py:190} INFO - OpenAI API call failed: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-DrJA6EhxcamxWcrd61odhGBX on tokens per min (TPM): Limit 30000, Requested 45426. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
[2025-05-13T20:03:23.828+0000] {logging_mixin.py:190} INFO - [Chunk 2] LLM response missing or failed.
[2025-05-13T20:03:23.893+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:03:24.320+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2022/ALNY_8-K_2022-10-27_0001157523-22-001411.txt
[2025-05-13T20:03:24.419+0000] {logging_mixin.py:190} INFO - Uploaded 10-Q filing to GCS: gs://clinical_data_may25/ALNY/10-Q/2022/ALNY_10-Q_2022-10-27_0001178670-22-000026.txt
[2025-05-13T20:03:24.759+0000] {logging_mixin.py:190} INFO - Finished processing: 0001157523-22-001411
[2025-05-13T20:03:24.759+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-22-246487
[2025-05-13T20:03:24.841+0000] {logging_mixin.py:190} INFO - Finished processing: 0001178670-22-000026
[2025-05-13T20:03:24.842+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-22-243702
[2025-05-13T20:03:25.399+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:25.400+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 2.318000 seconds
[2025-05-13T20:03:25.798+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:03:26.237+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2022/ALNY_8-K_2022-09-13_0001193125-22-243702.txt
[2025-05-13T20:03:26.710+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-22-243702
[2025-05-13T20:03:26.711+0000] {logging_mixin.py:190} INFO - Processing filing: 0001193125-22-228534
[2025-05-13T20:03:27.231+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-05-13T20:03:27.686+0000] {logging_mixin.py:190} INFO - Uploaded 8-K filing to GCS: gs://clinical_data_may25/ALNY/8-K/2022/ALNY_8-K_2022-08-24_0001193125-22-228534.txt
[2025-05-13T20:03:27.873+0000] {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[2025-05-13T20:03:27.882+0000] {_base_client.py:1085} INFO - Retrying request to /chat/completions in 4.760000 seconds
[2025-05-13T20:03:28.180+0000] {logging_mixin.py:190} INFO - Finished processing: 0001193125-22-228534
[2025-05-13T20:03:28.181+0000] {logging_mixin.py:190} INFO - Processing filing: 0001178670-22-000020
[2025-05-13T20:03:29.567+0000] {process_utils.py:150} WARNING - process psutil.Process(pid=3273, name='airflow task ru', status='sleeping', started='20:01:53') did not respond to SIGTERM. Trying SIGKILL
[2025-05-13T20:03:30.394+0000] {process_utils.py:87} INFO - Sending the signal 9 to group 3273
[2025-05-13T20:03:32.392+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=3273, name='airflow task ru', status='terminated', exitcode=<Negsignal.SIGKILL: -9>, started='20:01:53') (3273) terminated with exit code -9
[2025-05-13T20:03:32.500+0000] {standard_task_runner.py:190} ERROR - ('Job 104 was killed before it finished (likely due to running out of memory)', 'For more information, see https://***.apache.org/docs/apache-***/stable/troubleshooting.html#LocalTaskJob-killed')
