[2025-05-13T05:44:53.295+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-05-13T05:44:53.375+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sec_filing_scheduler.process_alny manual__2025-05-13T05:44:26.893773+00:00 [queued]>
[2025-05-13T05:44:53.430+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sec_filing_scheduler.process_alny manual__2025-05-13T05:44:26.893773+00:00 [queued]>
[2025-05-13T05:44:53.432+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2025-05-13T05:44:53.492+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): process_alny> on 2025-05-13 05:44:26.893773+00:00
[2025-05-13T05:44:53.599+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=997) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-05-13T05:44:53.626+0000] {standard_task_runner.py:72} INFO - Started process 1006 to run task
[2025-05-13T05:44:53.684+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'sec_filing_scheduler', 'process_alny', 'manual__2025-05-13T05:44:26.893773+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/orchestrate_clinical_pipeline.py', '--cfg-path', '/tmp/tmpkoit9tm0']
[2025-05-13T05:44:53.690+0000] {standard_task_runner.py:105} INFO - Job 15: Subtask process_alny
[2025-05-13T05:44:54.042+0000] {task_command.py:467} INFO - Running <TaskInstance: sec_filing_scheduler.process_alny manual__2025-05-13T05:44:26.893773+00:00 [running]> on host a05bfec3be05
[2025-05-13T05:44:54.852+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sec_filing_scheduler' AIRFLOW_CTX_TASK_ID='process_alny' AIRFLOW_CTX_EXECUTION_DATE='2025-05-13T05:44:26.893773+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-13T05:44:26.893773+00:00'
[2025-05-13T05:44:54.903+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-05-13T05:44:55.008+0000] {connection.py:277} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2025-05-13T05:44:55.011+0000] {base.py:84} INFO - Retrieving connection 'google_cloud_default'
[2025-05-13T05:44:55.397+0000] {logging_mixin.py:190} INFO - Failed to read processed accessions: 403 GET https://storage.googleapis.com/storage/v1/b/clinical_data_may06/o/ALNY%2Ftrack_ALNY_filings.json?fields=name&prettyPrint=false: 982882644329-compute@developer.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).
[2025-05-13T05:44:56.725+0000] {logging_mixin.py:190} INFO - Found 141 8-K filings
[2025-05-13T05:44:56.726+0000] {logging_mixin.py:190} INFO - Found 13 10-K filings
[2025-05-13T05:44:56.727+0000] {logging_mixin.py:190} INFO - Found 37 10-Q filings
[2025-05-13T05:44:56.729+0000] {logging_mixin.py:190} INFO - Found 191 new filings.
[2025-05-13T05:44:56.735+0000] {logging_mixin.py:190} INFO - Processing 1 filings...
[2025-05-13T05:45:00.736+0000] {log.py:232} WARNING - [92m05:45:00 - LiteLLM:INFO[0m: utils.py:2870 - 
LiteLLM completion() model= gemini-2.5-pro-preview-05-06; provider = vertex_ai
[2025-05-13T05:45:00.736+0000] {utils.py:2870} INFO - 
LiteLLM completion() model= gemini-2.5-pro-preview-05-06; provider = vertex_ai
[2025-05-13T05:45:00.746+0000] {log.py:232} WARNING - [92m05:45:00 - LiteLLM:ERROR[0m: vertex_llm_base.py:290 - Failed to load vertex credentials. Check to see if credentials containing partial/invalid information.
Traceback (most recent call last):
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 286, in get_access_token
    _credentials, credential_project_id = self.load_auth(
                                          ^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 95, in load_auth
    creds, creds_project_id = google_auth.default(
                              ^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 663, in default
    credentials, project_id = checker()
                              ^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 656, in <lambda>
    lambda: _get_explicit_environ_credentials(quota_project_id=quota_project_id),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 271, in _get_explicit_environ_credentials
    credentials, project_id = load_credentials_from_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 114, in load_credentials_from_file
    raise exceptions.DefaultCredentialsError(
google.auth.exceptions.DefaultCredentialsError: File D:\Kcap\backend\gcp\clinical-data-keys.json was not found.
[2025-05-13T05:45:00.744+0000] {vertex_llm_base.py:290} ERROR - Failed to load vertex credentials. Check to see if credentials containing partial/invalid information.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 286, in get_access_token
    _credentials, credential_project_id = self.load_auth(
                                          ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 95, in load_auth
    creds, creds_project_id = google_auth.default(
                              ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 663, in default
    credentials, project_id = checker()
                              ^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 656, in <lambda>
    lambda: _get_explicit_environ_credentials(quota_project_id=quota_project_id),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 271, in _get_explicit_environ_credentials
    credentials, project_id = load_credentials_from_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 114, in load_credentials_from_file
    raise exceptions.DefaultCredentialsError(
google.auth.exceptions.DefaultCredentialsError: File D:\Kcap\backend\gcp\clinical-data-keys.json was not found.
[2025-05-13T05:45:00.749+0000] {logging_mixin.py:190} INFO - Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
[2025-05-13T05:45:00.751+0000] {logging_mixin.py:190} INFO - LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.
[2025-05-13T05:45:00.806+0000] {logging_mixin.py:190} INFO - Finished 1/1: 0001178670-25-000052
[2025-05-13T05:45:00.812+0000] {log.py:232} WARNING - [92m05:45:00 - LiteLLM:INFO[0m: utils.py:2870 - 
LiteLLM completion() model= gemini-2.5-flash-preview-04-17; provider = vertex_ai
[2025-05-13T05:45:00.812+0000] {utils.py:2870} INFO - 
LiteLLM completion() model= gemini-2.5-flash-preview-04-17; provider = vertex_ai
[2025-05-13T05:45:00.825+0000] {log.py:232} WARNING - [92m05:45:00 - LiteLLM:ERROR[0m: vertex_llm_base.py:290 - Failed to load vertex credentials. Check to see if credentials containing partial/invalid information.
Traceback (most recent call last):
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 286, in get_access_token
    _credentials, credential_project_id = self.load_auth(
                                          ^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 95, in load_auth
    creds, creds_project_id = google_auth.default(
                              ^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 663, in default
    credentials, project_id = checker()
                              ^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 656, in <lambda>
    lambda: _get_explicit_environ_credentials(quota_project_id=quota_project_id),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 271, in _get_explicit_environ_credentials
    credentials, project_id = load_credentials_from_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 114, in load_credentials_from_file
    raise exceptions.DefaultCredentialsError(
google.auth.exceptions.DefaultCredentialsError: File D:\Kcap\backend\gcp\clinical-data-keys.json was not found.
[2025-05-13T05:45:00.818+0000] {vertex_llm_base.py:290} ERROR - Failed to load vertex credentials. Check to see if credentials containing partial/invalid information.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 286, in get_access_token
    _credentials, credential_project_id = self.load_auth(
                                          ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 95, in load_auth
    creds, creds_project_id = google_auth.default(
                              ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 663, in default
    credentials, project_id = checker()
                              ^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 656, in <lambda>
    lambda: _get_explicit_environ_credentials(quota_project_id=quota_project_id),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 271, in _get_explicit_environ_credentials
    credentials, project_id = load_credentials_from_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 114, in load_credentials_from_file
    raise exceptions.DefaultCredentialsError(
google.auth.exceptions.DefaultCredentialsError: File D:\Kcap\backend\gcp\clinical-data-keys.json was not found.
[2025-05-13T05:45:00.827+0000] {logging_mixin.py:190} INFO - Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
[2025-05-13T05:45:00.828+0000] {logging_mixin.py:190} INFO - LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.
[2025-05-13T05:45:00.879+0000] {logging_mixin.py:190} INFO - Error processing filings: litellm.APIConnectionError: File D:\Kcap\backend\gcp\clinical-data-keys.json was not found.
Traceback (most recent call last):
  File "/home/***/.local/lib/python3.12/site-packages/litellm/main.py", line 2500, in completion
    model_response = vertex_chat_completion.completion(  # type: ignore
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py", line 1436, in completion
    _auth_header, vertex_project = self._ensure_access_token(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 135, in _ensure_access_token
    return self.get_access_token(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 293, in get_access_token
    raise e
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 286, in get_access_token
    _credentials, credential_project_id = self.load_auth(
                                          ^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 95, in load_auth
    creds, creds_project_id = google_auth.default(
                              ^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 663, in default
    credentials, project_id = checker()
                              ^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 656, in <lambda>
    lambda: _get_explicit_environ_credentials(quota_project_id=quota_project_id),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 271, in _get_explicit_environ_credentials
    credentials, project_id = load_credentials_from_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 114, in load_credentials_from_file
    raise exceptions.DefaultCredentialsError(
google.auth.exceptions.DefaultCredentialsError: File D:\Kcap\backend\gcp\clinical-data-keys.json was not found.
[2025-05-13T05:45:01.355+0000] {logging_mixin.py:190} INFO - Failed to update processed accessions in GCS: 403 POST https://storage.googleapis.com/upload/storage/v1/b/clinical_data_may06/o?uploadType=multipart: {
  "error": {
    "code": 403,
    "message": "982882644329-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
    "errors": [
      {
        "message": "982882644329-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
        "domain": "global",
        "reason": "forbidden"
      }
    ]
  }
}
: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>)
[2025-05-13T05:45:01.376+0000] {logging_mixin.py:190} INFO - Deleted output_dir: sec_data/ALNY
[2025-05-13T05:45:01.384+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-05-13T05:45:01.441+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-05-13T05:45:01.444+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=sec_filing_scheduler, task_id=process_alny, run_id=manual__2025-05-13T05:44:26.893773+00:00, execution_date=20250513T054426, start_date=20250513T054453, end_date=20250513T054501
[2025-05-13T05:45:01.594+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-05-13T05:45:01.686+0000] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-13T05:45:01.702+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
