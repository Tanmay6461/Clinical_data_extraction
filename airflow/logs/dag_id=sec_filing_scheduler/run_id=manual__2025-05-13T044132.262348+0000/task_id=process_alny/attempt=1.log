[2025-05-13T04:41:54.077+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-05-13T04:41:54.118+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sec_filing_scheduler.process_alny manual__2025-05-13T04:41:32.262348+00:00 [queued]>
[2025-05-13T04:41:54.193+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sec_filing_scheduler.process_alny manual__2025-05-13T04:41:32.262348+00:00 [queued]>
[2025-05-13T04:41:54.194+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2025-05-13T04:41:54.236+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): process_alny> on 2025-05-13 04:41:32.262348+00:00
[2025-05-13T04:41:54.367+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=177) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-05-13T04:41:54.433+0000] {standard_task_runner.py:72} INFO - Started process 178 to run task
[2025-05-13T04:41:54.464+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'sec_filing_scheduler', 'process_alny', 'manual__2025-05-13T04:41:32.262348+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/orchestrate_clinical_pipeline.py', '--cfg-path', '/tmp/tmp0hcmyaxm']
[2025-05-13T04:41:54.468+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask process_alny
[2025-05-13T04:41:54.822+0000] {task_command.py:467} INFO - Running <TaskInstance: sec_filing_scheduler.process_alny manual__2025-05-13T04:41:32.262348+00:00 [running]> on host a05bfec3be05
[2025-05-13T04:41:55.293+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sec_filing_scheduler' AIRFLOW_CTX_TASK_ID='process_alny' AIRFLOW_CTX_EXECUTION_DATE='2025-05-13T04:41:32.262348+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-13T04:41:32.262348+00:00'
[2025-05-13T04:41:55.300+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-05-13T04:41:55.457+0000] {connection.py:277} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2025-05-13T04:41:55.459+0000] {base.py:84} INFO - Retrieving connection 'google_cloud_default'
[2025-05-13T04:41:56.020+0000] {logging_mixin.py:190} INFO - Failed to read processed accessions: 403 GET https://storage.googleapis.com/storage/v1/b/clinical_data_may06/o/ALNY%2Ftrack_ALNY_filings.json?fields=name&prettyPrint=false: 982882644329-compute@developer.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).
[2025-05-13T04:41:57.616+0000] {logging_mixin.py:190} INFO - Found 141 8-K filings
[2025-05-13T04:41:57.622+0000] {logging_mixin.py:190} INFO - Found 13 10-K filings
[2025-05-13T04:41:57.625+0000] {logging_mixin.py:190} INFO - Found 37 10-Q filings
[2025-05-13T04:41:57.627+0000] {logging_mixin.py:190} INFO - Found 191 new filings.
[2025-05-13T04:41:57.628+0000] {logging_mixin.py:190} INFO - Processing 191 filings...
[2025-05-13T04:42:05.866+0000] {log.py:232} WARNING - [92m04:42:05 - LiteLLM:INFO[0m: utils.py:2870 - 
LiteLLM completion() model= gemini-2.5-pro-preview-05-06; provider = vertex_ai
[2025-05-13T04:42:05.865+0000] {utils.py:2870} INFO - 
LiteLLM completion() model= gemini-2.5-pro-preview-05-06; provider = vertex_ai
[2025-05-13T04:42:05.978+0000] {log.py:232} WARNING - [92m04:42:05 - LiteLLM:ERROR[0m: vertex_llm_base.py:290 - Failed to load vertex credentials. Check to see if credentials containing partial/invalid information.
Traceback (most recent call last):
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 286, in get_access_token
    _credentials, credential_project_id = self.load_auth(
                                          ^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 95, in load_auth
    creds, creds_project_id = google_auth.default(
                              ^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 663, in default
    credentials, project_id = checker()
                              ^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 656, in <lambda>
    lambda: _get_explicit_environ_credentials(quota_project_id=quota_project_id),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 271, in _get_explicit_environ_credentials
    credentials, project_id = load_credentials_from_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/***/.local/lib/python3.12/site-packages/google/auth/_default.py", line 114, in load_credentials_from_file
    raise exceptions.DefaultCredentialsError(
google.auth.exceptions.DefaultCredentialsError: File D:\Kcap\backend\gcp\clinical-data-keys.json was not found.
[2025-05-13T04:42:05.963+0000] {vertex_llm_base.py:290} ERROR - Failed to load vertex credentials. Check to see if credentials containing partial/invalid information.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 286, in get_access_token
    _credentials, credential_project_id = self.load_auth(
                                          ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py", line 95, in load_auth
    creds, creds_project_id = google_auth.default(
                              ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 663, in default
    credentials, project_id = checker()
                              ^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 656, in <lambda>
    lambda: _get_explicit_environ_credentials(quota_project_id=quota_project_id),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 271, in _get_explicit_environ_credentials
    credentials, project_id = load_credentials_from_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/auth/_default.py", line 114, in load_credentials_from_file
    raise exceptions.DefaultCredentialsError(
google.auth.exceptions.DefaultCredentialsError: File D:\Kcap\backend\gcp\clinical-data-keys.json was not found.
[2025-05-13T04:42:05.985+0000] {logging_mixin.py:190} INFO - Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
[2025-05-13T04:42:05.986+0000] {logging_mixin.py:190} INFO - LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.
[2025-05-13T04:42:06.233+0000] {logging_mixin.py:190} INFO - Finished 1/191: 0001178670-25-000052
[2025-05-13T04:42:06.239+0000] {logging_mixin.py:190} INFO - Error processing filings: [Errno 2] No such file or directory: 'sec_data/ALNY/ALNY_drug_facts_partial.json'
[2025-05-13T04:42:06.515+0000] {logging_mixin.py:190} INFO - Failed to update processed accessions in GCS: 403 POST https://storage.googleapis.com/upload/storage/v1/b/clinical_data_may06/o?uploadType=multipart: {
  "error": {
    "code": 403,
    "message": "982882644329-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
    "errors": [
      {
        "message": "982882644329-compute@developer.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).",
        "domain": "global",
        "reason": "forbidden"
      }
    ]
  }
}
: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>)
[2025-05-13T04:42:06.520+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-05-13T04:42:06.578+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-05-13T04:42:06.579+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=sec_filing_scheduler, task_id=process_alny, run_id=manual__2025-05-13T04:41:32.262348+00:00, execution_date=20250513T044132, start_date=20250513T044154, end_date=20250513T044206
[2025-05-13T04:42:06.666+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-05-13T04:42:06.697+0000] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-13T04:42:06.706+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
